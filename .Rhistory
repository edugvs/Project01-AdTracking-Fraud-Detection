# Plotando gráfico para visualizar o nível de importância de cada variável no processo de predição da variável alvo.
plot_rf <- as.data.frame(varImpPlot(model1))
# Captura em ordem decrescente de nível de importância o nome das variáveis.
names <- rownames(plot_rf[order(plot_rf$MeanDecreaseAccuracy, decreasing = T),])
# Imprime o resultado.
plot_rf[order(plot_rf$MeanDecreaseAccuracy, decreasing = T),]
pred1 <- predict(model1, test)
# Computa a confusionMatrix gerada a partir do modelo criado.
caret::confusionMatrix(test$is_attributed, predictions, positive = '1')
# Computa a confusionMatrix gerada a partir do modelo criado.
caret::confusionMatrix(test$is_attributed, pred1, positive = '1')
f <- is_attributed ~ device + app + channel + ip + os
model_rf <- randomForest(f,
ntree      = 15,
nodesize   = 2,
data       = train)
pred2 <- predict(model_rf, test, type = 'response')
confusionMatrix(table(pred = pred2, data = test$is_attributed))
library(pROC)
rfAuc <- auc(roc(as.integer(test$is_attributed), as.integer(pred)))
# Exibe o resultado.
rfAuc
rfAuc <- auc(roc(as.integer(test$is_attributed), as.integer(pred)))
rfAuc <- auc(roc(as.integer(test$is_attributed), as.integer(pred2)))
rfAuc
plot_rf[order(plot_rf$MeanDecreaseAccuracy, decreasing = T),]
plot_rf <- as.data.frame(varImpPlot(model1))
library(randomForest)
plot_rf <- as.data.frame(varImpPlot(model1))
f <- is_attributed ~ device + app + channel + os
# Criando o modelo baseado no algoritmo Random Forest.
model_rf <- randomForest(f,
ntree      = 15,
nodesize   = 2,
data       = train)
# Realizando as previsões com o modelo baseado no algoritmo Random Forest.
pred2 <- predict(model_rf, test, type = 'response')
# Criando a Confusion Matrix a partir das previsões.
confusionMatrix(table(pred = pred2, data = test$is_attributed))
# Houve uma ligeira melhora no modelo após a seleção das variáveis
# Calculando a AUC para o modelo.
library(pROC)
rfAUC <- auc(roc(as.integer(test$is_attributed), as.integer(pred2)))
rfAUC
library(caret)
library(randomForest)
library(smotefamily)
confusionMatrix(table(pred = pred2, data = test$is_attributed))
View(train)
df_test <- fread('test_sample.csv')
library(data.table)
library(dplyr)
library(ggplot2)
library(dplyr)
library(lubridate)
library(fasttime)
df_test <- fread('test_sample.csv')
df_test <- fread('test.csv')
df_test <- fread('test.csv')
# Fazendo um copia do dataset
data_test <- df_test
# Carregando os dados de treino
df_original <- fread('train_sample.csv')
head(df_original)
glimpse(df_original)
summary(df_original)
# Fazendo um copia do dataset
data <- df_original
## Dicionario de dados ##
# Segundo a documentação, cada linha dos dados de treinamento contém um registro de clique e as seguintes vari[aveis:
#ip: define o endereço IP do clique;
#app: ID do aplicativo ao qual o anúncio se refere;
#device: ID do tipo de dispositivo do celular do usuário (por exemplo, iphone 6 plus, iphone 7, huawei mate 7 etc.);
#os: ID da versão do sistema operacional do telefone móvel do usuário;
#channel: ID do canal do editor de anúncios para celular;
#click_time: registro de data e hora do clique (UTC);
#attributed_time: se o usuário baixar o aplicativo após clicar em um anúncio, registra o instante de tempo em que o download do aplicativo foi realizado;
#is_attributed: variável alvo a ser prevista, e indica se o aplicativo foi ou não baixado.
#Observação: as variáveis ip, app, device, os, e channel estão codificadas.
# Transformando o tipo das variaveis
# Convertendo a variável click_time para o tipo date.
data$click_time <- fastPOSIXct(data$click_time)
# Convertendo a variável attributed_time para o tipo date.
data$attributed_time <- fastPOSIXct(data$attributed_time)
table(duplicated(data))
# Eliminando registros duplicados do dataset.
data <- data[!duplicated(data), ]
library(caret)
library(randomForest)
library(smotefamily)
train_data <- data %>%
mutate(day = day(click_time), hour = hour(click_time), min = minute(click_time), sec = second(click_time)) %>%
select(-c(click_time, attributed_time))
# Convertando a var target para tipo factor
train_data$is_attributed <- as.factor(train_data$is_attributed)
str(train_data)
# Normalizando os dados
library(scales)
dados_norm <- as.data.frame(lapply(train_data[, -6], rescale))
train_data <- cbind(train_data[,6], dados_norm)
# Balanceamento de classes
library(imbalance)
new.sample <- rwo(train_data, numInstances = 99545, classAttr = "is_attributed")
train_data <- rbind(train_data, new.sample)
table(new.sample$is_attributed)
table(train_data$is_attributed)
df_train <- fread('train_sample.csv')
head(df_original)
glimpse(df_original)
summary(df_original)
# Fazendo um copia do dataset
train_data <- df_original
## Dicionario de dados ##
# Segundo a documentação, cada linha dos dados de treinamento contém um registro de clique e as seguintes vari[aveis:
#ip: define o endereço IP do clique;
#app: ID do aplicativo ao qual o anúncio se refere;
#device: ID do tipo de dispositivo do celular do usuário (por exemplo, iphone 6 plus, iphone 7, huawei mate 7 etc.);
#os: ID da versão do sistema operacional do telefone móvel do usuário;
#channel: ID do canal do editor de anúncios para celular;
#click_time: registro de data e hora do clique (UTC);
#attributed_time: se o usuário baixar o aplicativo após clicar em um anúncio, registra o instante de tempo em que o download do aplicativo foi realizado;
#is_attributed: variável alvo a ser prevista, e indica se o aplicativo foi ou não baixado.
#Observação: as variáveis ip, app, device, os, e channel estão codificadas.
# Transformando o tipo das variaveis
# Convertendo a variável click_time para o tipo date.
train_data$click_time <- fastPOSIXct(train_data$click_time)
# Convertendo a variável attributed_time para o tipo date.
train_data$attributed_time <- fastPOSIXct(train_data$attributed_time)
## 3 - Limpeza dos dados ##
# Verificando valores ausentes no df
library(Amelia)
missmap(train_data,
main = "Training Data - Missing Values Map",
col = c("yellow", "black"),
legend = FALSE)
# Existem vários valores ausentes na variável "attributed_time", como a maioria dos registros os usuários NÃO fizeram o download
# do app, o tempo não foi registrado e a coluna fica com valores ausentes.
# Verificando a existência de registros duplicados.
table(duplicated(train_data))
# Eliminando registros duplicados do dataset.
train_data <- train_data[!duplicated(train_data), ]
## 4 - Analise exploratoria dos dados ##
# Checando o dataset
glimpse(train_data)
df_train <- fread('train_sample.csv')
head(df_train)
glimpse(df_train)
summary(df_train)
# Fazendo um copia do dataset
train_data <- df_train
# Convertendo a variável click_time para o tipo date.
train_data$click_time <- fastPOSIXct(train_data$click_time)
# Convertendo a variável attributed_time para o tipo date.
train_data$attributed_time <- fastPOSIXct(train_data$attributed_time)
# Verificando a existência de registros duplicados.
table(duplicated(train_data))
# Eliminando registros duplicados do dataset.
train_data <- train_data[!duplicated(train_data), ]
glimpse(train_data)
plot_var <- c("os", "channel", "device", "app", "attributed_time", "click_time", "ip")
train_data[, lapply(.SD, uniqueN), .SDcols = plot_var] %>%
melt(variable.name = "features", value.name = "unique_values") %>%
ggplot(aes(reorder(features, -unique_values), unique_values)) +
geom_bar(stat = "identity", fill = "steelblue") +
scale_y_log10(breaks = c(50,100,250, 500, 10000, 50000)) +
geom_text(aes(label = unique_values), vjust = 1.6, color = "white", size=3.5) +
theme_minimal() +
labs(x = "features", y = "Number of unique values")
table(train_data$is_attributed)
train_data %>%
mutate(Downloaded = factor(is_attributed, labels = c('No', 'Yes')))  %>%
ggplot(aes(x = Downloaded, fill = Downloaded)) +
geom_bar() +
labs(title = 'Var Target (is_attributed) Balancing') +
ylab('rows') +
theme_minimal()
train_data[, .N, by = os][order(-N)][1:10] %>%
ggplot(aes(reorder(os, -N), N)) +
geom_bar(stat="identity", fill="steelblue") +
theme_minimal() +
geom_text(aes(label = round(N / sum(N), 2)), vjust = 1.6, color = "white", size=2.5) +
labs(x = "os") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
train_data[, .N, by = channel][order(-N)][1:10] %>%
ggplot(aes(reorder(channel, -N), N)) +
geom_bar(stat="identity", fill="steelblue") +
theme_minimal() +
geom_text(aes(label = round(N / sum(N), 2)), vjust = 1.6, color = "white", size=2.5) +
labs(x = "channel") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
train_data[, .N, by = device][order(-N)][1:10] %>%
ggplot(aes(reorder(device, -N), N)) +
geom_bar(stat="identity", fill="steelblue") +
theme_minimal() +
geom_text(aes(label = round(N / sum(N), 2)), vjust = 1.6, color = "white", size=2.5) +
labs(x = "device") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
train_data[, .N, by = app][order(-N)][1:10] %>%
ggplot(aes(reorder(app, -N), N)) +
geom_bar(stat="identity", fill="steelblue") +
theme_minimal() +
geom_text(aes(label = round(N / sum(N), 2)), vjust = 1.6, color = "white", size=2.5) +
labs(x = "app") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Analisando series temporais
summary(train_data$click_time)
# Analisando o número de cliques que resultaram em download
train_data %>%
mutate(dates = floor_date(click_time, unit = 'hour')) %>%
group_by(dates) %>%
summarise(downloads = sum(as.numeric(is_attributed==1))) %>%
ggplot(aes(x = dates, y = downloads)) +
geom_line() +
scale_x_datetime(date_breaks = '2 hours', date_labels = '%d %b - %H') +
theme_minimal() +
theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
xlab('Time') +
ylab('Total Downloads') +
labs(title = 'Downloads per hour')
# Analisando o número de cliques que NÃO resultaram em download
train_data %>%
mutate(dates = floor_date(click_time, unit = 'hour')) %>%
group_by(dates) %>%
summarise(nodownloads = sum(!is_attributed)) %>%
ggplot(aes(x = dates, y = nodownloads)) +
geom_line() +
scale_x_datetime(date_breaks = '2 hours', date_labels = '%d %b - %H') +
theme_minimal() +
theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
xlab('Time') +
ylab('Unrealized downloads') +
labs(title = 'Unrealized downloads per hours')
# Verificando a diferença em segundos entre o clique e o momento em que o donwload foi executado
secs_diff <- difftime(train_data$attributed_time, train_data$click_time, units="secs")
secs_diff <- na.omit(secs_diff)
summary(as.numeric(secs_diff))
# Convertando a var target para tipo factor
train$is_attributed <- as.factor(train$is_attributed)
str(train)
# Normalizando os dados
library(scales)
dados_norm <- as.data.frame(lapply(train[, -6], rescale))
train <- cbind(train[,6], dados_norm)
# Balanceamento de classes
library(imbalance)
new.sample <- rwo(train, numInstances = 99545, classAttr = "is_attributed")
train <- rbind(train, new.sample)
table(new.sample$is_attributed)
table(train$is_attributed)
# Vamos separar a variável click_date em dia e hora e add a var secs_diff
train <- train_data %>%
mutate(day = day(click_time), hour = hour(click_time), min = minute(click_time), sec = second(click_time)) %>%
select(-c(click_time, attributed_time))
train$is_attributed <- as.factor(train$is_attributed)
str(train)
dados_norm <- as.data.frame(lapply(train[, -6], rescale))
train <- cbind(train[,6], dados_norm)
new.sample <- rwo(train, numInstances = 99545, classAttr = "is_attributed")
train <- rbind(train, new.sample)
table(new.sample$is_attributed)
table(train$is_attributed)
str(train)
df_test <- fread('test.csv')
test_data <- df_test
test_data$click_time <- fastPOSIXct(test_data$click_time)
# Convertendo a variável attributed_time para o tipo date.
test_data$attributed_time <- fastPOSIXct(test_data$attributed_time)
# Verificando a existência de registros duplicados.
table(duplicated(test_data))
# Eliminando registros duplicados do dataset.
test_data <- test_data[!duplicated(test_data), ]
secs_diff <- difftime(test_data$attributed_time, test_data$click_time, units="secs")
secs_diff <- na.omit(secs_diff)
summary(as.numeric(secs_diff))
View(test_data)
View(train_data)
# Vamos separar a variável click_date em dia e hora e add a var secs_diff
test <- test_data %>%
mutate(day = day(click_time), hour = hour(click_time), min = minute(click_time), sec = second(click_time)) %>%
select(-c(click_time, attributed_time))
# Convertando a var target para tipo factor
test$is_attributed <- as.factor(test$is_attributed)
str(test)
table(new.sample$is_attributed)
table(test$is_attributed)
table(test$is_attributed)
table(new.sample$is_attributed)
table(test$is_attributed)
View(test)
train = train
test = test
str(train)
str(test)
f <- is_attributed ~ device + app + channel + os
# Criando o modelo baseado no algoritmo Random Forest.
model_rf <- randomForest(f,
ntree      = 15,
nodesize   = 2,
data       = train)
pred2 <- predict(model_rf, test, type = 'response')
confusionMatrix(table(pred = pred2, data = test$is_attributed))
pred2
confusionMatrix(table(pred = pred2, data = test$is_attributed))
confusionMatrix(table(pred = pred2, data = test))
confusionMatrix(table(pred = pred2, data = test$click_id))
rfAUC <- auc(roc(as.integer(test$is_attributed), as.integer(pred2)))
# Construindo um Modelo Preditivo para Detecção de Fraudes no Tráfego de Cliques  em Propagandas de Aplicações Mobile
# Configurando o diretório de trabalho
# Coloque entre aspas o diretório de trabalho que você está usando no seu computador
setwd('C:/Users/Pichau/OneDrive/Cursos Online/FCD/1-Big-Data-Analytics-com-R-e-Microsoft-Azure-Machine-Learning/Cap20-Projetos-feedback/Projeto1')
getwd()
## 1 - Problema de negocio ##
# Neste projeto, iremos construir um modelo de aprendizado de máquina para determinar se um clique é
# fraudulento ou não. Para a construção desse projeto, utilizaremos a linguagem R.
# O dataset esta disponível no Kaggle no link:
#https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/data
## 2 - Carregando dados ##
# Importando as bibliotecas necessarias
library(data.table)
library(dplyr)
library(ggplot2)
library(dplyr)
library(lubridate)
library(fasttime)
# Carregando os dados de treino
df_original <- fread('train_sample.csv')
head(df_original)
glimpse(df_original)
summary(df_original)
# Fazendo um copia do dataset
data <- df_original
## Dicionario de dados ##
# Segundo a documentação, cada linha dos dados de treinamento contém um registro de clique e as seguintes vari[aveis:
#ip: define o endereço IP do clique;
#app: ID do aplicativo ao qual o anúncio se refere;
#device: ID do tipo de dispositivo do celular do usuário (por exemplo, iphone 6 plus, iphone 7, huawei mate 7 etc.);
#os: ID da versão do sistema operacional do telefone móvel do usuário;
#channel: ID do canal do editor de anúncios para celular;
#click_time: registro de data e hora do clique (UTC);
#attributed_time: se o usuário baixar o aplicativo após clicar em um anúncio, registra o instante de tempo em que o download do aplicativo foi realizado;
#is_attributed: variável alvo a ser prevista, e indica se o aplicativo foi ou não baixado.
#Observação: as variáveis ip, app, device, os, e channel estão codificadas.
# Transformando o tipo das variaveis
# Convertendo a variável click_time para o tipo date.
data$click_time <- fastPOSIXct(data$click_time)
# Convertendo a variável attributed_time para o tipo date.
data$attributed_time <- fastPOSIXct(data$attributed_time)
## 3 - Limpeza dos dados ##
# Verificando valores ausentes no df
library(Amelia)
missmap(data,
main = "Training Data - Missing Values Map",
col = c("yellow", "black"),
legend = FALSE)
# Existem vários valores ausentes na variável "attributed_time", como a maioria dos registros os usuários NÃO fizeram o download
# do app, o tempo não foi registrado e a coluna fica com valores ausentes.
# Verificando a existência de registros duplicados.
table(duplicated(data))
# Eliminando registros duplicados do dataset.
data <- data[!duplicated(data), ]
## 4 - Analise exploratoria dos dados ##
# Checando o dataset
glimpse(data)
# Verificando os valores únicos para cada variavel
plot_var <- c("os", "channel", "device", "app", "attributed_time", "click_time", "ip")
data[, lapply(.SD, uniqueN), .SDcols = plot_var] %>%
melt(variable.name = "features", value.name = "unique_values") %>%
ggplot(aes(reorder(features, -unique_values), unique_values)) +
geom_bar(stat = "identity", fill = "steelblue") +
scale_y_log10(breaks = c(50,100,250, 500, 10000, 50000)) +
geom_text(aes(label = unique_values), vjust = 1.6, color = "white", size=3.5) +
theme_minimal() +
labs(x = "features", y = "Number of unique values")
# Analisando a variavel target
table(data$is_attributed)
data %>%
mutate(Downloaded = factor(is_attributed, labels = c('No', 'Yes')))  %>%
ggplot(aes(x = Downloaded, fill = Downloaded)) +
geom_bar() +
labs(title = 'Var Target (is_attributed) Balancing') +
ylab('rows') +
theme_minimal()
#Podemos observar que a classe está desbalanceada então devemos executar um balanceamento de classes.
# Explorando as variáveis categóricas
data[, .N, by = os][order(-N)][1:10] %>%
ggplot(aes(reorder(os, -N), N)) +
geom_bar(stat="identity", fill="steelblue") +
theme_minimal() +
geom_text(aes(label = round(N / sum(N), 2)), vjust = 1.6, color = "white", size=2.5) +
labs(x = "os") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
data[, .N, by = channel][order(-N)][1:10] %>%
ggplot(aes(reorder(channel, -N), N)) +
geom_bar(stat="identity", fill="steelblue") +
theme_minimal() +
geom_text(aes(label = round(N / sum(N), 2)), vjust = 1.6, color = "white", size=2.5) +
labs(x = "channel") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
data[, .N, by = device][order(-N)][1:10] %>%
ggplot(aes(reorder(device, -N), N)) +
geom_bar(stat="identity", fill="steelblue") +
theme_minimal() +
geom_text(aes(label = round(N / sum(N), 2)), vjust = 1.6, color = "white", size=2.5) +
labs(x = "device") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
data[, .N, by = app][order(-N)][1:10] %>%
ggplot(aes(reorder(app, -N), N)) +
geom_bar(stat="identity", fill="steelblue") +
theme_minimal() +
geom_text(aes(label = round(N / sum(N), 2)), vjust = 1.6, color = "white", size=2.5) +
labs(x = "app") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Analisando series temporais
summary(data$click_time)
# Analisando o número de cliques que resultaram em download
data %>%
mutate(dates = floor_date(click_time, unit = 'hour')) %>%
group_by(dates) %>%
summarise(downloads = sum(as.numeric(is_attributed==1))) %>%
ggplot(aes(x = dates, y = downloads)) +
geom_line() +
scale_x_datetime(date_breaks = '2 hours', date_labels = '%d %b - %H') +
theme_minimal() +
theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
xlab('Time') +
ylab('Total Downloads') +
labs(title = 'Downloads per hour')
# Analisando o número de cliques que NÃO resultaram em download
data %>%
mutate(dates = floor_date(click_time, unit = 'hour')) %>%
group_by(dates) %>%
summarise(nodownloads = sum(!is_attributed)) %>%
ggplot(aes(x = dates, y = nodownloads)) +
geom_line() +
scale_x_datetime(date_breaks = '2 hours', date_labels = '%d %b - %H') +
theme_minimal() +
theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
xlab('Time') +
ylab('Unrealized downloads') +
labs(title = 'Unrealized downloads per hours')
# Verificando a diferença em segundos entre o clique e o momento em que o donwload foi executado
secs_diff <- difftime(data$attributed_time, data$click_time, units="secs")
secs_diff <- na.omit(secs_diff)
summary(as.numeric(secs_diff))
## Criando o Modelo Preditivo ##
library(caret)
library(randomForest)
library(smotefamily)
# Feature Engineering
# Vamos separar a variável click_date em dia e hora e add a var secs_diff
train_data <- data %>%
mutate(day = day(click_time), hour = hour(click_time), min = minute(click_time), sec = second(click_time)) %>%
select(-c(click_time, attributed_time))
# Convertando a var target para tipo factor
train_data$is_attributed <- as.factor(train_data$is_attributed)
str(train_data)
# Normalizando os dados
library(scales)
dados_norm <- as.data.frame(lapply(train_data[, -6], rescale))
train_data <- cbind(train_data[,6], dados_norm)
# Balanceamento de classes
library(imbalance)
new.sample <- rwo(train_data, numInstances = 99545, classAttr = "is_attributed")
train_data <- rbind(train_data, new.sample)
table(new.sample$is_attributed)
table(train_data$is_attributed)
# Dividindo o dataset em treino e teste
library(caTools)
split = sample.split(train_data$is_attributed, SplitRatio = 0.70)
train = subset(train_data, split==TRUE)
test = subset(train_data, split==FALSE)
str(train)
str(test)
# Verificando a importancia das variaveis usando o RandomForrest
# Define um seed para permitir que os mesmos resultados dos experimentos sejam reproduzíveis.
set.seed(100)
model1 <- randomForest(is_attributed ~ .,
data       = train,
ntree      = 15,
nodesize   = 2,
importance = T)
# Imprime o modelo
model1
# Plotando gráfico para visualizar o nível de importância de cada variável no processo de predição da variável alvo.
plot_rf <- as.data.frame(varImpPlot(model1))
# Captura em ordem decrescente de nível de importância o nome das variáveis.
names <- rownames(plot_rf[order(plot_rf$MeanDecreaseAccuracy, decreasing = T),])
# Imprime o resultado.
plot_rf[order(plot_rf$MeanDecreaseAccuracy, decreasing = T),]
# Fazendo as previsões
pred1 <- predict(model1, test)
# Computa a confusionMatrix gerada a partir do modelo criado.
caret::confusionMatrix(test$is_attributed, pred1, positive = '1')
# Construindo o modelo com as variáveis mais relevantes
# Definindo fórmula a ser utilizada pelo modelo.
f <- is_attributed ~ device + app + channel + ip + os
# Criando o modelo baseado no algoritmo Random Forest.
model_rf <- randomForest(f,
ntree      = 15,
nodesize   = 2,
data       = train)
# Realizando as previsões com o modelo baseado no algoritmo Random Forest.
pred2 <- predict(model_rf, test, type = 'response')
# Criando a Confusion Matrix a partir das previsões.
confusionMatrix(table(pred = pred2, data = test$is_attributed))
# Houve uma ligeira melhora no modelo após a seleção das variáveis
# Calculando a AUC para o modelo.
library(pROC)
rfAUC <- auc(roc(as.integer(test$is_attributed), as.integer(pred2)))
rfAUC
table(new.sample$is_attributed)
table(train_data$is_attributed)
